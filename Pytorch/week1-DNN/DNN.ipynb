{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7d0ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3f6cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lhe339/Documents/GitHub/study/Pytorch/week1-DNN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a84df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:1.13.1\n",
      "MPS 장치를 지원하도록 build 되었는지: True\n",
      "MPS 장치가 사용 가능한지: True\n",
      "macOS-13.0-arm64-arm-64bit\r\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print (f\"PyTorch version:{torch.__version__}\") # 1.12.1 이상\n",
    "print(f\"MPS 장치를 지원하도록 build 되었는지: {torch.backends.mps.is_built()}\") # True 여야 합니다.\n",
    "print(f\"MPS 장치가 사용 가능한지: {torch.backends.mps.is_available()}\") # True 여야 합니다.\n",
    "!python -c 'import platform;print(platform.platform())'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa8a4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2623</td>\n",
       "      <td>194</td>\n",
       "      <td>12</td>\n",
       "      <td>404</td>\n",
       "      <td>3</td>\n",
       "      <td>1664</td>\n",
       "      <td>218</td>\n",
       "      <td>250</td>\n",
       "      <td>164</td>\n",
       "      <td>1879</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2526</td>\n",
       "      <td>228</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>1075</td>\n",
       "      <td>190</td>\n",
       "      <td>254</td>\n",
       "      <td>196</td>\n",
       "      <td>1639</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2650</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>424</td>\n",
       "      <td>43</td>\n",
       "      <td>1031</td>\n",
       "      <td>232</td>\n",
       "      <td>225</td>\n",
       "      <td>126</td>\n",
       "      <td>934</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2126</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>202</td>\n",
       "      <td>207</td>\n",
       "      <td>140</td>\n",
       "      <td>582</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2368</td>\n",
       "      <td>57</td>\n",
       "      <td>11</td>\n",
       "      <td>180</td>\n",
       "      <td>8</td>\n",
       "      <td>376</td>\n",
       "      <td>228</td>\n",
       "      <td>216</td>\n",
       "      <td>120</td>\n",
       "      <td>700</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2623     194     12                               404   \n",
       "1       2526     228     18                                67   \n",
       "2       2650      82      8                               424   \n",
       "3       2126      10     16                                 0   \n",
       "4       2368      57     11                               180   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               3                             1664   \n",
       "1                              12                             1075   \n",
       "2                              43                             1031   \n",
       "3                               0                              834   \n",
       "4                               8                              376   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            218             250            164   \n",
       "1            190             254            196   \n",
       "2            232             225            126   \n",
       "3            202             207            140   \n",
       "4            228             216            120   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                1879  ...            0            0   \n",
       "1                                1639  ...            0            0   \n",
       "2                                 934  ...            0            0   \n",
       "3                                 582  ...            0            0   \n",
       "4                                 700  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           3  \n",
       "1            0            0           3  \n",
       "2            0            0           3  \n",
       "3            0            0           3  \n",
       "4            0            0           3  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "data_cov = pd.read_csv('covtype.csv')\n",
    "data_cov['Cover_Type'].value_counts()\n",
    "#class1 == 3, class0 == 4\n",
    "data1= data_cov[data_cov['Cover_Type'] == 3]\n",
    "data0 = data_cov[data_cov['Cover_Type'] == 4]\n",
    "\n",
    "df = pd.concat([data1,data0])\n",
    "\n",
    "dataset=df.sample(frac=1).reset_index(drop=True) #샘플 섞어주기\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4502f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Cover_Type'].replace([3, 4],[1, 0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74724701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35754\n",
       "0     2747\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Cover_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009dba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('Cover_Type', axis =1)\n",
    "y = dataset['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec04859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.224633</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>-0.951564</td>\n",
       "      <td>1.391801</td>\n",
       "      <td>-0.978979</td>\n",
       "      <td>1.202810</td>\n",
       "      <td>0.352511</td>\n",
       "      <td>1.241121</td>\n",
       "      <td>0.486867</td>\n",
       "      <td>1.854108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.731035</td>\n",
       "      <td>0.509983</td>\n",
       "      <td>-0.288476</td>\n",
       "      <td>-0.940593</td>\n",
       "      <td>-0.826885</td>\n",
       "      <td>0.221817</td>\n",
       "      <td>-0.342776</td>\n",
       "      <td>1.386750</td>\n",
       "      <td>1.093080</td>\n",
       "      <td>1.396182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.362026</td>\n",
       "      <td>-0.858049</td>\n",
       "      <td>-1.393623</td>\n",
       "      <td>1.530222</td>\n",
       "      <td>-0.303006</td>\n",
       "      <td>0.148534</td>\n",
       "      <td>0.700154</td>\n",
       "      <td>0.330940</td>\n",
       "      <td>-0.233011</td>\n",
       "      <td>0.051025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.304421</td>\n",
       "      <td>-1.532695</td>\n",
       "      <td>-0.509506</td>\n",
       "      <td>-1.404303</td>\n",
       "      <td>-1.029677</td>\n",
       "      <td>-0.179575</td>\n",
       "      <td>-0.044796</td>\n",
       "      <td>-0.324391</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>-0.620600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.072971</td>\n",
       "      <td>-1.092301</td>\n",
       "      <td>-1.062079</td>\n",
       "      <td>-0.158514</td>\n",
       "      <td>-0.894482</td>\n",
       "      <td>-0.942385</td>\n",
       "      <td>0.600828</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>-0.346676</td>\n",
       "      <td>-0.395453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   1.224633  0.191400 -0.951564                          1.391801   \n",
       "1   0.731035  0.509983 -0.288476                         -0.940593   \n",
       "2   1.362026 -0.858049 -1.393623                          1.530222   \n",
       "3  -1.304421 -1.532695 -0.509506                         -1.404303   \n",
       "4  -0.072971 -1.092301 -1.062079                         -0.158514   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                       -0.978979                         1.202810   \n",
       "1                       -0.826885                         0.221817   \n",
       "2                       -0.303006                         0.148534   \n",
       "3                       -1.029677                        -0.179575   \n",
       "4                       -0.894482                        -0.942385   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0       0.352511        1.241121       0.486867   \n",
       "1      -0.342776        1.386750       1.093080   \n",
       "2       0.700154        0.330940      -0.233011   \n",
       "3      -0.044796       -0.324391       0.032207   \n",
       "4       0.600828        0.003275      -0.346676   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type31  Soil_Type32  \\\n",
       "0                            1.854108  ...          0.0    -0.052543   \n",
       "1                            1.396182  ...          0.0    -0.052543   \n",
       "2                            0.051025  ...          0.0    -0.052543   \n",
       "3                           -0.620600  ...          0.0    -0.052543   \n",
       "4                           -0.395453  ...          0.0    -0.052543   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0    -0.011397          0.0          0.0          0.0          0.0   \n",
       "1    -0.011397          0.0          0.0          0.0          0.0   \n",
       "2    -0.011397          0.0          0.0          0.0          0.0   \n",
       "3    -0.011397          0.0          0.0          0.0          0.0   \n",
       "4    -0.011397          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_scaled = scaler.transform(X) \n",
    "\n",
    "scaled_df = pd.DataFrame(X_scaled, columns=X.columns) \n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d5d388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/2db9ylzj0cd11s7tz69zggtm0000gn/T/ipykernel_3238/1137587587.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  dataset = pd.concat([scaled_df,y],1)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.concat([scaled_df,y],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a12403dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Modeling: (23101, 55)\n",
      "Unseen Data For Predictions: (15400, 55)\n"
     ]
    }
   ],
   "source": [
    "# 신규 (테스트) 데이터 생성 \n",
    "data = dataset.sample(frac=0.6, random_state=786)\n",
    "data_test = dataset.drop(data.index)\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('Data for Modeling: ' + str(data.shape))\n",
    "print('Unseen Data For Predictions: ' + str(data_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8abee495",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, test_size = 0.3, random_state = 9492)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ed266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu') #gpu를 사용할 수 있으면 사용하고, 아니면 cpu를 사용하겠다\n",
    "print(f\"device: {device}\")\n",
    "train_x = train.iloc[:,:-1]\n",
    "train_y = train.iloc[:,-1]\n",
    "val_x = val.iloc[:,:-1]\n",
    "val_y = val.iloc[:,-1]\n",
    "\n",
    "trn_y  = torch.FloatTensor(train_y.values)\n",
    "trn_X  = torch.FloatTensor(train_x.values)\n",
    "val_y  = torch.FloatTensor(val_y.values)\n",
    "val_X  = torch.FloatTensor(val_x.values)\n",
    "\n",
    "\n",
    "train = TensorDataset(trn_X, trn_y)\n",
    "val  = TensorDataset(val_X, val_y)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_kwargs = {'dataset': train,\n",
    "                'batch_size': batch_size,\n",
    "               'shuffle': True}\n",
    "test_kwargs = {'dataset': val,\n",
    "                'batch_size': batch_size,\n",
    "              'shuffle': False}\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(**train_kwargs)\n",
    "val_loader  = torch.utils.data.DataLoader(**test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c1f70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 사용\n",
    "use_mps = torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8163f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_size, output_size, drop_rate):\n",
    "#         super(DNN, self).__init__() #nn.Module 상속 받음\n",
    "        \n",
    "#         layer1 = [nn.Linear(input_size, 48),\n",
    "#                  nn.BatchNorm1d(48),\n",
    "#                  nn.Dropout(drop_rate),\n",
    "#                  nn.ReLU()]\n",
    "        \n",
    "#         layer2 = [nn.Linear(48, 24),\n",
    "#                  nn.BatchNorm1d(24),\n",
    "#                  nn.Dropout(drop_rate),\n",
    "#                  nn.ReLU()]\n",
    "        \n",
    "#         layer3 = [nn.Linear(24, 12),\n",
    "#                  nn.BatchNorm1d(12),\n",
    "#                  nn.Dropout(drop_rate),\n",
    "#                  nn.ReLU()]\n",
    "        \n",
    "#         layer4 = [nn.Linear(12, output_size),\n",
    "#                  nn.Sigmoid()]\n",
    "        \n",
    "#         self.fisrt_layer = nn.Sequential(*layer1)\n",
    "#         self.second_layer = nn.Sequential(*layer2)\n",
    "#         self.third_layer = nn.Sequential(*layer3)\n",
    "#         self.last_layer = nn.Sequential(*layer4)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.fisrt_layer(x)\n",
    "#         x = self.second_layer(x)\n",
    "#         x = self.third_layer(x)\n",
    "#         out = self.last_layer(x)\n",
    "\n",
    "#         return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19a04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_kwargs = {'drop_rate': 0.56,\n",
    "#               'input_size': 54,\n",
    "#                'output_size': 1}\n",
    "\n",
    "# training_kwargs = {'learning_rate': 1e-3,\n",
    "#               'epoch': 100}\n",
    "\n",
    "# model = DNN(**model_kwargs).to(device)\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=training_kwargs['learning_rate'])\n",
    "\n",
    "# num_epochs = training_kwargs['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561194c7",
   "metadata": {},
   "source": [
    "- nn.BCELoss()는 이진 분류(binary classification) 문제에서 사용하는 손실 함수 중 하나입니다.<br> BCE는 Binary Cross Entropy의 약자이며, 이 함수는 실제 타겟값과 예측값 사이의 차이를 계산합니다.<br>\n",
    "\n",
    "- 이 손실 함수는 주로 출력값이 0 또는 1인 이진 분류 문제에서 사용됩니다.<br> 예를 들어, 스팸 메일 분류 문제에서 이메일이 스팸인지 아닌지를 예측하는 이진 분류 문제를 생각해 볼 수 있습니다.<br> 이 경우, nn.BCELoss() 함수는 모델의 출력값과 실제 타겟값 간의 차이를 측정하여 모델을 훈련합니다.<br>\n",
    "\n",
    "- 이 손실 함수를 사용하는 이유는 모델이 예측을 잘못할 때 더 큰 페널티를 부여하기 위해서입니다.<br> BCELoss 함수는 모델이 예측을 맞춘 경우에는 작은 손실값을 반환하고, 예측을 잘못한 경우에는 더 큰 손실값을 반환합니다.<br> 따라서 모델은 정확한 예측을 하기 위해 노력하게 됩니다.<br>\n",
    "\n",
    "- 이진 분류 문제에서 nn.BCELoss() 함수는 일반적으로 시그모이드 활성화 함수와 함께 사용됩니다.<br> 시그모이드 함수는 0과 1 사이의 값을 출력하기 때문에, 이진 분류 문제에서 모델의 출력값을 나타내는데 적합합니다.<br> nn.BCELoss() 함수는 모델의 출력값과 타겟값 간의 차이를 계산하여 손실값을 반환합니다.<br> 이 손실값은 모델을 훈련하는 동안 역전파(backpropagation)를 통해 사용되며, 모델의 가중치를 업데이트합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bd349",
   "metadata": {},
   "source": [
    "- nn.BCELoss() 함수의 수식은 다음과 같습니다.\n",
    "\n",
    "$$(x, y) = -\\frac{1}{N}\\sum_{i=1}^{N}(y_i\\log(x_i) %2B (1-y_i)\\log(1-x_i))\"$$\n",
    "\n",
    "- 여기서 $x$는 모델이 예측한 이진 분류 결과이고, $y$는 실제 이진 분류 결과입니다.<br> 이 식은 모든 데이터 포인트 $i$에 대한 손실값을 계산합니다.\n",
    "\n",
    "- BCELoss 함수는 각 데이터 포인트 $i$의 손실을 계산하기 위해 크로스 엔트로피(cross-entropy) 손실 함수를 사용합니다.<br> 이 손실 함수는 실제 타겟값과 예측값 사이의 차이를 계산하는데, 이진 분류 문제에서는 $y$가 $0$일 때는 $1-x$, $y$가 $1$일 때는 $x$를 계산하여 사용합니다.\n",
    "\n",
    "- 이 손실 함수는 모델의 예측값이 실제 타겟값과 가까울수록 손실값이 작아지도록 학습됩니다.<br> 모델이 정확하게 예측하는 경우 손실값은 $0$에 가까워집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb36803",
   "metadata": {},
   "source": [
    "- Adam(Adaptive Moment Estimation)은 최적화 알고리즘 중 하나로, 딥러닝 모델 학습에 널리 사용됩니다.<br> Adam은 RMSprop과 모멘텀 최적화 방법을 결합한 알고리즘으로, 각각의 파라미터마다 적응적인 학습률(adaptive learning rate)을 사용하여 학습을 진행합니다.\n",
    "\n",
    "- Adam의 핵심 아이디어는 다음과 같습니다.\n",
    "\n",
    "1. 모멘텀 최적화 방법처럼, 이전 스텝에서의 gradient 정보를 이용하여 이번 스텝에서의 gradient 값을 업데이트합니다.<br> 이를 통해 일정 방향으로 gradient를 누적하면서 빠르게 수렴하도록 합니다.\n",
    "\n",
    "2. RMSprop 방법처럼, 각각의 파라미터마다 적응적인 학습률을 적용합니다.<br> 즉, 각 파라미터마다 gradient 크기에 대한 이동 평균을 구하고, 이를 통해 학습률을 조절합니다.<br> 이를 통해 각 파라미터마다 적절한 학습률을 적용하여, 수렴 속도와 성능을 개선할 수 있습니다.\n",
    "\n",
    "3. 위의 방법들을 조합하여, 이전 gradient의 이동 평균과 누적된 gradient 값을 이용하여 적응적인 학습률을 계산합니다.<br> 즉, 이전 스텝에서의 gradient 정보와 현재 스텝에서의 gradient 정보를 이용하여, 보다 빠르고 안정적으로 수렴하도록 합니다.\n",
    "\n",
    "- Adam은 이러한 아이디어를 바탕으로, 적응적인 학습률을 사용하면서도 모멘텀 최적화 방법과 비슷한 수렴 속도와 성능을 보이는 것으로 알려져 있습니다.<br> 따라서, 딥러닝 모델 학습에 자주 사용되는 최적화 알고리즘 중 하나입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b82760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Neural network')\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd4fc27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import copy\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\") \n",
    "# #loss\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# def train(model, device, train_loader, optimizer, epoch):\n",
    "#     global criterion\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data) #output: 64 x 1\n",
    "#         output = output.squeeze(1) #output: 64\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "# def test():\n",
    "#     global criterion\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         n_correct = 0\n",
    "#         n_samples = 0\n",
    "#         for batch_idx, (data, target) in enumerate (val_loader):\n",
    "#             valid_loss = {'loss_val' : []}\n",
    "            \n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             outputs = model(data)\n",
    "#             outputs = outputs.squeeze()\n",
    "            \n",
    "#             loss_val = criterion(outputs, target)\n",
    "#             valid_loss['loss_val'].append(loss_val.item())\n",
    "            \n",
    "#             outputs = torch.flatten(outputs).cpu().detach().numpy()\n",
    "#             target = torch.flatten(target).cpu().detach().numpy()\n",
    "#             predicted = np.where(outputs>0.5, 1, 0)\n",
    "            \n",
    "#             n_samples += len(target)\n",
    "#             n_correct += (predicted == target).sum().item()\n",
    "#             vl_mean = np.array(valid_loss['loss_val']).mean()\n",
    "            \n",
    "#             if batch_idx % 100 == 0:\n",
    "#                 print('Batch mean Validation Loss: {:.6f}'.format(vl_mean))\n",
    "\n",
    "#     acc = 100.0 * n_correct / n_samples\n",
    "#     print(f'Accuracy of the network on the 10000 validation set: {acc} %')\n",
    "#     return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47919320",
   "metadata": {},
   "source": [
    "- 위 코드에서 copy 모듈은 딥러닝 모델의 가중치(weight)와 편향(bias) 등의 매개변수를 복사(copy)하는 데 사용됩니다.\n",
    "\n",
    "- best_model = copy.deepcopy(model)은 현재의 딥러닝 모델 model을 깊은 복사(deep copy)하여 best_model에 저장합니다.<br> 깊은 복사는 객체를 완전히 새로운 객체로 복사하는 방법으로, 원본 객체와 복사본 객체가 서로 독립적이고 다른 객체가 됩니다.<br> 이렇게 복사본을 생성하는 이유는, 만약 모델의 매개변수를 직접 수정하면 원본 모델도 영향을 받기 때문입니다.<br> 이러한 문제를 피하기 위해, 깊은 복사를 통해 복사본을 생성하고 복사본을 수정하여 사용합니다.\n",
    "\n",
    "- 따라서, 위 코드에서는 현재 모델의 성능이 이전 모델의 성능보다 우수할 경우, 현재 모델의 매개변수를 best_model에 저장합니다.<br> 이후 best_model은 이전의 모델과는 완전히 별개의 객체이기 때문에, 이후에 이 객체를 사용하여 학습을 진행해도 이전의 모델에는 영향을 미치지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33bdbe",
   "metadata": {},
   "source": [
    "- 딥러닝 모델을 학습할 때, 손실 함수(loss function)는 학습하는 동안 반복적으로 사용되는 함수 중 하나입니다.<br> 따라서, 일반적으로 손실 함수는 딥러닝 모델과 별도로 정의하여 사용됩니다.<br> 위 코드에서 criterion = nn.BCELoss()는 이러한 손실 함수를 정의한 부분입니다.\n",
    "\n",
    "- train() 함수에서 global criterion이라는 문장이 포함된 이유는, train() 함수 내에서 손실 함수를 사용하기 위해 전역 변수(global variable)로서 criterion 변수를 사용하려는 것입니다.<br> 이렇게 전역 변수로 선언해두면, train() 함수 내에서 따로 criterion을 지정해주지 않아도 전역 변수로 정의된 손실 함수를 사용할 수 있습니다.\n",
    "\n",
    "- 딥러닝 모델에서 사용되는 매개변수와 손실 함수는 딥러닝 모델의 학습에 있어 중요한 역할을 합니다.<br> 따라서, 이러한 매개변수와 손실 함수는 모델 학습 시 정의되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bf0982a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OUTPUT_PATH = '/Users/lhe339/Documents/GitHub/study/Pytorch/week1-DNN'\n",
    "# best_acc = -1\n",
    "# best_model = None\n",
    "# for epoch in range(0, num_epochs):\n",
    "#     train(model, device, train_loader, optimizer, epoch)\n",
    "#     acc = test()\n",
    "#     if acc > best_acc:\n",
    "#         best_acc = acc\n",
    "#         best_model = copy.deepcopy(model)\n",
    "#         print(f'new best acc={best_acc}')\n",
    "#     else:\n",
    "#         print(f'current acc={acc}, prev_best_acc={best_acc}')\n",
    "\n",
    "# state = {\n",
    "#     'model_state': best_model.state_dict(),\n",
    "#     'test_acc': best_acc\n",
    "# }\n",
    "# torch.save(state, OUTPUT_PATH+'/practice_nn.pt')  #훈련 끝나고 모델을 저장\n",
    "# print('best model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "234470f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #new data inference\n",
    "\n",
    "# x = torch.normal(mean=6.9671e-06, std=0.4746, size=(1,54))\n",
    "# out = model(x.to(device))\n",
    "# out = torch.flatten(out).cpu().detach().numpy()\n",
    "# predicted = np.where(out>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b701881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('예측 클래스:', predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd68085",
   "metadata": {},
   "source": [
    "## [HW] 3-layer neural network 를 구현하고 학습하세요(batch norm, drop out, activation function 자유 구성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c017364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class threee_layer_nn(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, drop_rate):\n",
    "        super(threee_layer_nn, self).__init__()\n",
    "        \n",
    "        layer1 = [nn.Linear(input_size, 128),\n",
    "                 nn.BatchNorm1d(128),\n",
    "                 nn.Dropout(drop_rate),\n",
    "                 nn.ReLU()]\n",
    "\n",
    "        layer2 = [nn.Linear(128, 64),\n",
    "                 nn.BatchNorm1d(64),\n",
    "                 nn.Dropout(drop_rate),\n",
    "                 nn.ReLU()]\n",
    "        \n",
    "        layer3 = [nn.Linear(64, output_size),\n",
    "                 nn.Sigmoid()]\n",
    "        \n",
    "        self.first_layer = nn.Sequential(*layer1)\n",
    "        self.second_layer = nn.Sequential(*layer2)\n",
    "        self.last_layer = nn.Sequential(*layer3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.first_layer(x)\n",
    "        x = self.second_layer(x)\n",
    "        out = self.last_layer(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f22da707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {'drop_rate' : 0.2,\n",
    "            'input_size' : 256,\n",
    "            'output_size' : 2}\n",
    "\n",
    "training_kwargs = {'learning_rate' : 1e-2,\n",
    "                 'epoch' : 10}\n",
    "\n",
    "model = threee_layer_nn(**model_kwargs).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=training_kwargs['learning_rate'])\n",
    "\n",
    "num_epochs = training_kwargs['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2da2a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threee_layer_nn(\n",
      "  (first_layer): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (second_layer): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (last_layer): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5777c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    global criterion\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        output = output.squeeze(1)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {}[{}/{} ({:.0f}%)]\\tLoss: {.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test():\n",
    "    global criterion\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for batch_idx, (data, target) in enumerate (val_loader):\n",
    "            valid_loss = {'loss_val' : []}\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            loss_val = criterion(outputs, target)\n",
    "            valid_loss['loss_val'].append(loss_val.item())\n",
    "            \n",
    "            outputs = torch.flatten(outputs).cpu().detach().numpy()\n",
    "            target = torch.flatten(target).cpu().detach().numpy()\n",
    "            predicted = np.where(outputs>0.5, 1, 0)\n",
    "            \n",
    "            n_samples += len(target)\n",
    "            n_correct += (predicted == target).sum().item()\n",
    "            vl_mean = np.array(valid_loss['loss_val']).mean()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Batch mean Validation Loss: {:.6f}'.format(vl_mean))\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 validation set: {acc} %')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '/Users/lhe339/Documents/GitHub/study/Pytorch/week1-DNN'\n",
    "best_acc = -1\n",
    "best_model = None\n",
    "for epoch in range(0, num_epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    acc = test()\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print(f'new best acc={best_acc}')\n",
    "    else:\n",
    "        print(f'current acc={acc}, prev_best_acc={best_acc}')\n",
    "\n",
    "state = {\n",
    "    'model_state': best_model.state_dict(),\n",
    "    'test_acc': best_acc\n",
    "}\n",
    "torch.save(state, OUTPUT_PATH+'/homework_nn.pt')  #훈련 끝나고 모델을 저장\n",
    "print('best model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new data inference\n",
    "\n",
    "x = torch.normal(mean=6.9671e-06, std=0.4746, size=(1,54))\n",
    "out = model(x.to(device))\n",
    "out = torch.flatten(out).cpu().detach().numpy()\n",
    "predicted = np.where(out>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a860eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('예측 클래스:', predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e040e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
