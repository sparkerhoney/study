{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d0ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc3f6cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lhe339/Documents/GitHub/study/Pytorch/week1-DNN'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a84df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:1.13.1\n",
      "MPS 장치를 지원하도록 build 되었는지: True\n",
      "MPS 장치가 사용 가능한지: True\n",
      "macOS-13.0-arm64-arm-64bit\r\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print (f\"PyTorch version:{torch.__version__}\") # 1.12.1 이상\n",
    "print(f\"MPS 장치를 지원하도록 build 되었는지: {torch.backends.mps.is_built()}\") # True 여야 합니다.\n",
    "print(f\"MPS 장치가 사용 가능한지: {torch.backends.mps.is_available()}\") # True 여야 합니다.\n",
    "!python -c 'import platform;print(platform.platform())'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa8a4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2466</td>\n",
       "      <td>313</td>\n",
       "      <td>25</td>\n",
       "      <td>285</td>\n",
       "      <td>174</td>\n",
       "      <td>376</td>\n",
       "      <td>146</td>\n",
       "      <td>213</td>\n",
       "      <td>203</td>\n",
       "      <td>711</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2062</td>\n",
       "      <td>69</td>\n",
       "      <td>27</td>\n",
       "      <td>150</td>\n",
       "      <td>53</td>\n",
       "      <td>242</td>\n",
       "      <td>236</td>\n",
       "      <td>177</td>\n",
       "      <td>55</td>\n",
       "      <td>247</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2298</td>\n",
       "      <td>309</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>319</td>\n",
       "      <td>161</td>\n",
       "      <td>223</td>\n",
       "      <td>200</td>\n",
       "      <td>543</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2260</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>342</td>\n",
       "      <td>216</td>\n",
       "      <td>191</td>\n",
       "      <td>103</td>\n",
       "      <td>1738</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2205</td>\n",
       "      <td>272</td>\n",
       "      <td>20</td>\n",
       "      <td>242</td>\n",
       "      <td>128</td>\n",
       "      <td>361</td>\n",
       "      <td>162</td>\n",
       "      <td>241</td>\n",
       "      <td>216</td>\n",
       "      <td>638</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2466     313     25                               285   \n",
       "1       2062      69     27                               150   \n",
       "2       2298     309     20                                42   \n",
       "3       2260      39     20                                30   \n",
       "4       2205     272     20                               242   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             174                              376   \n",
       "1                              53                              242   \n",
       "2                              10                              319   \n",
       "3                              15                              342   \n",
       "4                             128                              361   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            146             213            203   \n",
       "1            236             177             55   \n",
       "2            161             223            200   \n",
       "3            216             191            103   \n",
       "4            162             241            216   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                 711  ...            0            0   \n",
       "1                                 247  ...            0            0   \n",
       "2                                 543  ...            0            0   \n",
       "3                                1738  ...            0            0   \n",
       "4                                 638  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           3  \n",
       "1            0            0           3  \n",
       "2            0            0           3  \n",
       "3            0            0           3  \n",
       "4            0            0           3  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "data_cov = pd.read_csv('covtype.csv')\n",
    "data_cov['Cover_Type'].value_counts()\n",
    "#class1 == 3, class0 == 4\n",
    "data1= data_cov[data_cov['Cover_Type'] == 3]\n",
    "data0 = data_cov[data_cov['Cover_Type'] == 4]\n",
    "\n",
    "df = pd.concat([data1,data0])\n",
    "\n",
    "dataset=df.sample(frac=1).reset_index(drop=True) #샘플 섞어주기\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4502f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Cover_Type'].replace([3, 4],[1, 0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74724701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35754\n",
       "0     2747\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Cover_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009dba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('Cover_Type', axis =1)\n",
    "y = dataset['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec04859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425716</td>\n",
       "      <td>1.306440</td>\n",
       "      <td>0.485127</td>\n",
       "      <td>0.568196</td>\n",
       "      <td>1.910808</td>\n",
       "      <td>-0.942385</td>\n",
       "      <td>-1.435370</td>\n",
       "      <td>-0.105947</td>\n",
       "      <td>1.225689</td>\n",
       "      <td>-0.374465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.630094</td>\n",
       "      <td>-0.979860</td>\n",
       "      <td>0.706156</td>\n",
       "      <td>-0.366145</td>\n",
       "      <td>-0.134012</td>\n",
       "      <td>-1.165565</td>\n",
       "      <td>0.799481</td>\n",
       "      <td>-1.416608</td>\n",
       "      <td>-1.578047</td>\n",
       "      <td>-1.259788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.429175</td>\n",
       "      <td>1.268960</td>\n",
       "      <td>-0.067447</td>\n",
       "      <td>-1.113619</td>\n",
       "      <td>-0.860684</td>\n",
       "      <td>-1.037320</td>\n",
       "      <td>-1.062894</td>\n",
       "      <td>0.258125</td>\n",
       "      <td>1.168857</td>\n",
       "      <td>-0.695013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.622544</td>\n",
       "      <td>-1.260963</td>\n",
       "      <td>-0.067447</td>\n",
       "      <td>-1.196671</td>\n",
       "      <td>-0.776187</td>\n",
       "      <td>-0.999013</td>\n",
       "      <td>0.302848</td>\n",
       "      <td>-0.906907</td>\n",
       "      <td>-0.668727</td>\n",
       "      <td>1.585077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.902419</td>\n",
       "      <td>0.922267</td>\n",
       "      <td>-0.067447</td>\n",
       "      <td>0.270591</td>\n",
       "      <td>1.133438</td>\n",
       "      <td>-0.967368</td>\n",
       "      <td>-1.038063</td>\n",
       "      <td>0.913456</td>\n",
       "      <td>1.471963</td>\n",
       "      <td>-0.513751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052543</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   0.425716  1.306440  0.485127                          0.568196   \n",
       "1  -1.630094 -0.979860  0.706156                         -0.366145   \n",
       "2  -0.429175  1.268960 -0.067447                         -1.113619   \n",
       "3  -0.622544 -1.260963 -0.067447                         -1.196671   \n",
       "4  -0.902419  0.922267 -0.067447                          0.270591   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                        1.910808                        -0.942385   \n",
       "1                       -0.134012                        -1.165565   \n",
       "2                       -0.860684                        -1.037320   \n",
       "3                       -0.776187                        -0.999013   \n",
       "4                        1.133438                        -0.967368   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0      -1.435370       -0.105947       1.225689   \n",
       "1       0.799481       -1.416608      -1.578047   \n",
       "2      -1.062894        0.258125       1.168857   \n",
       "3       0.302848       -0.906907      -0.668727   \n",
       "4      -1.038063        0.913456       1.471963   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type31  Soil_Type32  \\\n",
       "0                           -0.374465  ...          0.0    -0.052543   \n",
       "1                           -1.259788  ...          0.0    -0.052543   \n",
       "2                           -0.695013  ...          0.0    -0.052543   \n",
       "3                            1.585077  ...          0.0    -0.052543   \n",
       "4                           -0.513751  ...          0.0    -0.052543   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0    -0.011397          0.0          0.0          0.0          0.0   \n",
       "1    -0.011397          0.0          0.0          0.0          0.0   \n",
       "2    -0.011397          0.0          0.0          0.0          0.0   \n",
       "3    -0.011397          0.0          0.0          0.0          0.0   \n",
       "4    -0.011397          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_scaled = scaler.transform(X) \n",
    "\n",
    "scaled_df = pd.DataFrame(X_scaled, columns=X.columns) \n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d5d388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/2db9ylzj0cd11s7tz69zggtm0000gn/T/ipykernel_1713/1137587587.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  dataset = pd.concat([scaled_df,y],1)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.concat([scaled_df,y],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a12403dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Modeling: (23101, 55)\n",
      "Unseen Data For Predictions: (15400, 55)\n"
     ]
    }
   ],
   "source": [
    "# 신규 (테스트) 데이터 생성 \n",
    "data = dataset.sample(frac=0.6, random_state=786)\n",
    "data_test = dataset.drop(data.index)\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('Data for Modeling: ' + str(data.shape))\n",
    "print('Unseen Data For Predictions: ' + str(data_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8abee495",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, test_size = 0.3, random_state = 9492)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ed266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu') #gpu를 사용할 수 있으면 사용하고, 아니면 cpu를 사용하겠다\n",
    "print(f\"device: {device}\")\n",
    "train_x = train.iloc[:,:-1]\n",
    "train_y = train.iloc[:,-1]\n",
    "val_x = val.iloc[:,:-1]\n",
    "val_y = val.iloc[:,-1]\n",
    "\n",
    "trn_y  = torch.FloatTensor(train_y.values)\n",
    "trn_X  = torch.FloatTensor(train_x.values)\n",
    "val_y  = torch.FloatTensor(val_y.values)\n",
    "val_X  = torch.FloatTensor(val_x.values)\n",
    "\n",
    "\n",
    "train = TensorDataset(trn_X, trn_y)\n",
    "val  = TensorDataset(val_X, val_y)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_kwargs = {'dataset': train,\n",
    "                'batch_size': batch_size,\n",
    "               'shuffle': True}\n",
    "test_kwargs = {'dataset': val,\n",
    "                'batch_size': batch_size,\n",
    "              'shuffle': False}\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(**train_kwargs)\n",
    "val_loader  = torch.utils.data.DataLoader(**test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c1f70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 사용\n",
    "use_mps = torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8163f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, drop_rate):\n",
    "        super(DNN, self).__init__() #nn.Module 상속 받음\n",
    "        \n",
    "        layer1 = [nn.Linear(input_size, 48),\n",
    "                 nn.BatchNorm1d(48),\n",
    "                 nn.Dropout(drop_rate),\n",
    "                 nn.ReLU()]\n",
    "        \n",
    "        layer2 = [nn.Linear(48, 24),\n",
    "                 nn.BatchNorm1d(24),\n",
    "                 nn.Dropout(drop_rate),\n",
    "                 nn.ReLU()]\n",
    "        \n",
    "        layer3 = [nn.Linear(24, 12),\n",
    "                 nn.BatchNorm1d(12),\n",
    "                 nn.Dropout(drop_rate),\n",
    "                 nn.ReLU()]\n",
    "        \n",
    "        layer4 = [nn.Linear(12, output_size),\n",
    "                 nn.Sigmoid()]\n",
    "        \n",
    "        self.fisrt_layer = nn.Sequential(*layer1)\n",
    "        self.second_layer = nn.Sequential(*layer2)\n",
    "        self.third_layer = nn.Sequential(*layer3)\n",
    "        self.last_layer = nn.Sequential(*layer4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fisrt_layer(x)\n",
    "        x = self.second_layer(x)\n",
    "        x = self.third_layer(x)\n",
    "        out = self.last_layer(x)\n",
    "\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a19a04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {'drop_rate': 0.56,\n",
    "              'input_size': 54,\n",
    "               'output_size': 1}\n",
    "\n",
    "training_kwargs = {'learning_rate': 1e-3,\n",
    "              'epoch': 100}\n",
    "\n",
    "model = DNN(**model_kwargs).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=training_kwargs['learning_rate'])\n",
    "\n",
    "num_epochs = training_kwargs['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561194c7",
   "metadata": {},
   "source": [
    "- nn.BCELoss()는 이진 분류(binary classification) 문제에서 사용하는 손실 함수 중 하나입니다.<br> BCE는 Binary Cross Entropy의 약자이며, 이 함수는 실제 타겟값과 예측값 사이의 차이를 계산합니다.<br>\n",
    "\n",
    "- 이 손실 함수는 주로 출력값이 0 또는 1인 이진 분류 문제에서 사용됩니다.<br> 예를 들어, 스팸 메일 분류 문제에서 이메일이 스팸인지 아닌지를 예측하는 이진 분류 문제를 생각해 볼 수 있습니다.<br> 이 경우, nn.BCELoss() 함수는 모델의 출력값과 실제 타겟값 간의 차이를 측정하여 모델을 훈련합니다.<br>\n",
    "\n",
    "- 이 손실 함수를 사용하는 이유는 모델이 예측을 잘못할 때 더 큰 페널티를 부여하기 위해서입니다.<br> BCELoss 함수는 모델이 예측을 맞춘 경우에는 작은 손실값을 반환하고, 예측을 잘못한 경우에는 더 큰 손실값을 반환합니다.<br> 따라서 모델은 정확한 예측을 하기 위해 노력하게 됩니다.<br>\n",
    "\n",
    "- 이진 분류 문제에서 nn.BCELoss() 함수는 일반적으로 시그모이드 활성화 함수와 함께 사용됩니다.<br> 시그모이드 함수는 0과 1 사이의 값을 출력하기 때문에, 이진 분류 문제에서 모델의 출력값을 나타내는데 적합합니다.<br> nn.BCELoss() 함수는 모델의 출력값과 타겟값 간의 차이를 계산하여 손실값을 반환합니다.<br> 이 손실값은 모델을 훈련하는 동안 역전파(backpropagation)를 통해 사용되며, 모델의 가중치를 업데이트합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bd349",
   "metadata": {},
   "source": [
    "- nn.BCELoss() 함수의 수식은 다음과 같습니다.\n",
    "\n",
    "$$(x, y) = -\\frac{1}{N}\\sum_{i=1}^{N}(y_i\\log(x_i) %2B (1-y_i)\\log(1-x_i))\"$$\n",
    "\n",
    "- 여기서 $x$는 모델이 예측한 이진 분류 결과이고, $y$는 실제 이진 분류 결과입니다.<br> 이 식은 모든 데이터 포인트 $i$에 대한 손실값을 계산합니다.\n",
    "\n",
    "- BCELoss 함수는 각 데이터 포인트 $i$의 손실을 계산하기 위해 크로스 엔트로피(cross-entropy) 손실 함수를 사용합니다.<br> 이 손실 함수는 실제 타겟값과 예측값 사이의 차이를 계산하는데, 이진 분류 문제에서는 $y$가 $0$일 때는 $1-x$, $y$가 $1$일 때는 $x$를 계산하여 사용합니다.\n",
    "\n",
    "- 이 손실 함수는 모델의 예측값이 실제 타겟값과 가까울수록 손실값이 작아지도록 학습됩니다.<br> 모델이 정확하게 예측하는 경우 손실값은 $0$에 가까워집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb36803",
   "metadata": {},
   "source": [
    "- Adam(Adaptive Moment Estimation)은 최적화 알고리즘 중 하나로, 딥러닝 모델 학습에 널리 사용됩니다.<br> Adam은 RMSprop과 모멘텀 최적화 방법을 결합한 알고리즘으로, 각각의 파라미터마다 적응적인 학습률(adaptive learning rate)을 사용하여 학습을 진행합니다.\n",
    "\n",
    "- Adam의 핵심 아이디어는 다음과 같습니다.\n",
    "\n",
    "1. 모멘텀 최적화 방법처럼, 이전 스텝에서의 gradient 정보를 이용하여 이번 스텝에서의 gradient 값을 업데이트합니다.<br> 이를 통해 일정 방향으로 gradient를 누적하면서 빠르게 수렴하도록 합니다.\n",
    "\n",
    "2. RMSprop 방법처럼, 각각의 파라미터마다 적응적인 학습률을 적용합니다.<br> 즉, 각 파라미터마다 gradient 크기에 대한 이동 평균을 구하고, 이를 통해 학습률을 조절합니다.<br> 이를 통해 각 파라미터마다 적절한 학습률을 적용하여, 수렴 속도와 성능을 개선할 수 있습니다.\n",
    "\n",
    "3. 위의 방법들을 조합하여, 이전 gradient의 이동 평균과 누적된 gradient 값을 이용하여 적응적인 학습률을 계산합니다.<br> 즉, 이전 스텝에서의 gradient 정보와 현재 스텝에서의 gradient 정보를 이용하여, 보다 빠르고 안정적으로 수렴하도록 합니다.\n",
    "\n",
    "- Adam은 이러한 아이디어를 바탕으로, 적응적인 학습률을 사용하면서도 모멘텀 최적화 방법과 비슷한 수렴 속도와 성능을 보이는 것으로 알려져 있습니다.<br> 따라서, 딥러닝 모델 학습에 자주 사용되는 최적화 알고리즘 중 하나입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b82760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network\n",
      "DNN(\n",
      "  (fisrt_layer): Sequential(\n",
      "    (0): Linear(in_features=54, out_features=48, bias=True)\n",
      "    (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.56, inplace=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (second_layer): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=24, bias=True)\n",
      "    (1): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.56, inplace=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (third_layer): Sequential(\n",
      "    (0): Linear(in_features=24, out_features=12, bias=True)\n",
      "    (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.56, inplace=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (last_layer): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('Neural network')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccd4fc27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "#loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    global criterion\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data) #output: 64 x 1\n",
    "        output = output.squeeze(1) #output: 64\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test():\n",
    "    global criterion\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for batch_idx, (data, target) in enumerate (val_loader):\n",
    "            valid_loss = {'loss_val' : []}\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            loss_val = criterion(outputs, target)\n",
    "            valid_loss['loss_val'].append(loss_val.item())\n",
    "            \n",
    "            outputs = torch.flatten(outputs).cpu().detach().numpy()\n",
    "            target = torch.flatten(target).cpu().detach().numpy()\n",
    "            predicted = np.where(outputs>0.5, 1, 0)\n",
    "            \n",
    "            n_samples += len(target)\n",
    "            n_correct += (predicted == target).sum().item()\n",
    "            vl_mean = np.array(valid_loss['loss_val']).mean()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Batch mean Validation Loss: {:.6f}'.format(vl_mean))\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 validation set: {acc} %')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47919320",
   "metadata": {},
   "source": [
    "- 위 코드에서 copy 모듈은 딥러닝 모델의 가중치(weight)와 편향(bias) 등의 매개변수를 복사(copy)하는 데 사용됩니다.\n",
    "\n",
    "- best_model = copy.deepcopy(model)은 현재의 딥러닝 모델 model을 깊은 복사(deep copy)하여 best_model에 저장합니다.<br> 깊은 복사는 객체를 완전히 새로운 객체로 복사하는 방법으로, 원본 객체와 복사본 객체가 서로 독립적이고 다른 객체가 됩니다.<br> 이렇게 복사본을 생성하는 이유는, 만약 모델의 매개변수를 직접 수정하면 원본 모델도 영향을 받기 때문입니다.<br> 이러한 문제를 피하기 위해, 깊은 복사를 통해 복사본을 생성하고 복사본을 수정하여 사용합니다.\n",
    "\n",
    "- 따라서, 위 코드에서는 현재 모델의 성능이 이전 모델의 성능보다 우수할 경우, 현재 모델의 매개변수를 best_model에 저장합니다.<br> 이후 best_model은 이전의 모델과는 완전히 별개의 객체이기 때문에, 이후에 이 객체를 사용하여 학습을 진행해도 이전의 모델에는 영향을 미치지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33bdbe",
   "metadata": {},
   "source": [
    "- 딥러닝 모델을 학습할 때, 손실 함수(loss function)는 학습하는 동안 반복적으로 사용되는 함수 중 하나입니다.<br> 따라서, 일반적으로 손실 함수는 딥러닝 모델과 별도로 정의하여 사용됩니다.<br> 위 코드에서 criterion = nn.BCELoss()는 이러한 손실 함수를 정의한 부분입니다.\n",
    "\n",
    "- train() 함수에서 global criterion이라는 문장이 포함된 이유는, train() 함수 내에서 손실 함수를 사용하기 위해 전역 변수(global variable)로서 criterion 변수를 사용하려는 것입니다.<br> 이렇게 전역 변수로 선언해두면, train() 함수 내에서 따로 criterion을 지정해주지 않아도 전역 변수로 정의된 손실 함수를 사용할 수 있습니다.\n",
    "\n",
    "- 딥러닝 모델에서 사용되는 매개변수와 손실 함수는 딥러닝 모델의 학습에 있어 중요한 역할을 합니다.<br> 따라서, 이러한 매개변수와 손실 함수는 모델 학습 시 정의되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bf0982a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/16170 (0%)]\tLoss: 0.119578\n",
      "Train Epoch: 0 [6400/16170 (40%)]\tLoss: 0.173841\n",
      "Train Epoch: 0 [12800/16170 (79%)]\tLoss: 0.124886\n",
      "Batch mean Validation Loss: 0.132663\n",
      "Batch mean Validation Loss: 0.124679\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "new best acc=93.04573654595296\n",
      "Train Epoch: 1 [0/16170 (0%)]\tLoss: 0.098543\n",
      "Train Epoch: 1 [6400/16170 (40%)]\tLoss: 0.162166\n",
      "Train Epoch: 1 [12800/16170 (79%)]\tLoss: 0.177617\n",
      "Batch mean Validation Loss: 0.135541\n",
      "Batch mean Validation Loss: 0.120917\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 2 [0/16170 (0%)]\tLoss: 0.106764\n",
      "Train Epoch: 2 [6400/16170 (40%)]\tLoss: 0.219544\n",
      "Train Epoch: 2 [12800/16170 (79%)]\tLoss: 0.227762\n",
      "Batch mean Validation Loss: 0.141803\n",
      "Batch mean Validation Loss: 0.119492\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 3 [0/16170 (0%)]\tLoss: 0.155561\n",
      "Train Epoch: 3 [6400/16170 (40%)]\tLoss: 0.098390\n",
      "Train Epoch: 3 [12800/16170 (79%)]\tLoss: 0.208146\n",
      "Batch mean Validation Loss: 0.139468\n",
      "Batch mean Validation Loss: 0.115969\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 4 [0/16170 (0%)]\tLoss: 0.125947\n",
      "Train Epoch: 4 [6400/16170 (40%)]\tLoss: 0.113267\n",
      "Train Epoch: 4 [12800/16170 (79%)]\tLoss: 0.112279\n",
      "Batch mean Validation Loss: 0.135719\n",
      "Batch mean Validation Loss: 0.112092\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 5 [0/16170 (0%)]\tLoss: 0.135641\n",
      "Train Epoch: 5 [6400/16170 (40%)]\tLoss: 0.143325\n",
      "Train Epoch: 5 [12800/16170 (79%)]\tLoss: 0.167867\n",
      "Batch mean Validation Loss: 0.119989\n",
      "Batch mean Validation Loss: 0.118231\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 6 [0/16170 (0%)]\tLoss: 0.151185\n",
      "Train Epoch: 6 [6400/16170 (40%)]\tLoss: 0.297569\n",
      "Train Epoch: 6 [12800/16170 (79%)]\tLoss: 0.128445\n",
      "Batch mean Validation Loss: 0.107225\n",
      "Batch mean Validation Loss: 0.125918\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 7 [0/16170 (0%)]\tLoss: 0.121229\n",
      "Train Epoch: 7 [6400/16170 (40%)]\tLoss: 0.110490\n",
      "Train Epoch: 7 [12800/16170 (79%)]\tLoss: 0.179013\n",
      "Batch mean Validation Loss: 0.105762\n",
      "Batch mean Validation Loss: 0.121660\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 8 [0/16170 (0%)]\tLoss: 0.105523\n",
      "Train Epoch: 8 [6400/16170 (40%)]\tLoss: 0.124225\n",
      "Train Epoch: 8 [12800/16170 (79%)]\tLoss: 0.138956\n",
      "Batch mean Validation Loss: 0.109759\n",
      "Batch mean Validation Loss: 0.120619\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 9 [0/16170 (0%)]\tLoss: 0.134651\n",
      "Train Epoch: 9 [6400/16170 (40%)]\tLoss: 0.147297\n",
      "Train Epoch: 9 [12800/16170 (79%)]\tLoss: 0.163740\n",
      "Batch mean Validation Loss: 0.106421\n",
      "Batch mean Validation Loss: 0.117279\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 10 [0/16170 (0%)]\tLoss: 0.130284\n",
      "Train Epoch: 10 [6400/16170 (40%)]\tLoss: 0.132516\n",
      "Train Epoch: 10 [12800/16170 (79%)]\tLoss: 0.240981\n",
      "Batch mean Validation Loss: 0.111778\n",
      "Batch mean Validation Loss: 0.113686\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 11 [0/16170 (0%)]\tLoss: 0.148758\n",
      "Train Epoch: 11 [6400/16170 (40%)]\tLoss: 0.120569\n",
      "Train Epoch: 11 [12800/16170 (79%)]\tLoss: 0.166954\n",
      "Batch mean Validation Loss: 0.107494\n",
      "Batch mean Validation Loss: 0.111223\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 12 [0/16170 (0%)]\tLoss: 0.112281\n",
      "Train Epoch: 12 [6400/16170 (40%)]\tLoss: 0.194380\n",
      "Train Epoch: 12 [12800/16170 (79%)]\tLoss: 0.131215\n",
      "Batch mean Validation Loss: 0.097975\n",
      "Batch mean Validation Loss: 0.109636\n",
      "Accuracy of the network on the 10000 validation set: 93.04573654595296 %\n",
      "current acc=93.04573654595296, prev_best_acc=93.04573654595296\n",
      "Train Epoch: 13 [0/16170 (0%)]\tLoss: 0.101906\n",
      "Train Epoch: 13 [6400/16170 (40%)]\tLoss: 0.081393\n",
      "Train Epoch: 13 [12800/16170 (79%)]\tLoss: 0.128585\n",
      "Batch mean Validation Loss: 0.099912\n",
      "Batch mean Validation Loss: 0.114854\n",
      "Accuracy of the network on the 10000 validation set: 93.23329966815756 %\n",
      "new best acc=93.23329966815756\n",
      "Train Epoch: 14 [0/16170 (0%)]\tLoss: 0.169412\n",
      "Train Epoch: 14 [6400/16170 (40%)]\tLoss: 0.225643\n",
      "Train Epoch: 14 [12800/16170 (79%)]\tLoss: 0.247297\n",
      "Batch mean Validation Loss: 0.097951\n",
      "Batch mean Validation Loss: 0.110092\n",
      "Accuracy of the network on the 10000 validation set: 93.06016447843024 %\n",
      "current acc=93.06016447843024, prev_best_acc=93.23329966815756\n",
      "Train Epoch: 15 [0/16170 (0%)]\tLoss: 0.121590\n",
      "Train Epoch: 15 [6400/16170 (40%)]\tLoss: 0.063305\n",
      "Train Epoch: 15 [12800/16170 (79%)]\tLoss: 0.118030\n",
      "Batch mean Validation Loss: 0.096102\n",
      "Batch mean Validation Loss: 0.106907\n",
      "Accuracy of the network on the 10000 validation set: 93.34872312797576 %\n",
      "new best acc=93.34872312797576\n",
      "Train Epoch: 16 [0/16170 (0%)]\tLoss: 0.160523\n",
      "Train Epoch: 16 [6400/16170 (40%)]\tLoss: 0.150621\n",
      "Train Epoch: 16 [12800/16170 (79%)]\tLoss: 0.139021\n",
      "Batch mean Validation Loss: 0.085888\n",
      "Batch mean Validation Loss: 0.117885\n",
      "Accuracy of the network on the 10000 validation set: 94.08454768431683 %\n",
      "new best acc=94.08454768431683\n",
      "Train Epoch: 17 [0/16170 (0%)]\tLoss: 0.313031\n",
      "Train Epoch: 17 [6400/16170 (40%)]\tLoss: 0.124622\n",
      "Train Epoch: 17 [12800/16170 (79%)]\tLoss: 0.164916\n",
      "Batch mean Validation Loss: 0.100592\n",
      "Batch mean Validation Loss: 0.097385\n",
      "Accuracy of the network on the 10000 validation set: 93.07459241090751 %\n",
      "current acc=93.07459241090751, prev_best_acc=94.08454768431683\n",
      "Train Epoch: 18 [0/16170 (0%)]\tLoss: 0.135588\n",
      "Train Epoch: 18 [6400/16170 (40%)]\tLoss: 0.220830\n",
      "Train Epoch: 18 [12800/16170 (79%)]\tLoss: 0.155516\n",
      "Batch mean Validation Loss: 0.102337\n",
      "Batch mean Validation Loss: 0.097149\n",
      "Accuracy of the network on the 10000 validation set: 93.37757899293031 %\n",
      "current acc=93.37757899293031, prev_best_acc=94.08454768431683\n",
      "Train Epoch: 19 [0/16170 (0%)]\tLoss: 0.088340\n",
      "Train Epoch: 19 [6400/16170 (40%)]\tLoss: 0.115673\n",
      "Train Epoch: 19 [12800/16170 (79%)]\tLoss: 0.134044\n",
      "Batch mean Validation Loss: 0.093105\n",
      "Batch mean Validation Loss: 0.106836\n",
      "Accuracy of the network on the 10000 validation set: 93.16116000577118 %\n",
      "current acc=93.16116000577118, prev_best_acc=94.08454768431683\n",
      "Train Epoch: 20 [0/16170 (0%)]\tLoss: 0.142161\n",
      "Train Epoch: 20 [6400/16170 (40%)]\tLoss: 0.146118\n",
      "Train Epoch: 20 [12800/16170 (79%)]\tLoss: 0.116369\n",
      "Batch mean Validation Loss: 0.084793\n",
      "Batch mean Validation Loss: 0.112606\n",
      "Accuracy of the network on the 10000 validation set: 94.14225941422595 %\n",
      "new best acc=94.14225941422595\n",
      "Train Epoch: 21 [0/16170 (0%)]\tLoss: 0.083136\n",
      "Train Epoch: 21 [6400/16170 (40%)]\tLoss: 0.122502\n",
      "Train Epoch: 21 [12800/16170 (79%)]\tLoss: 0.154249\n",
      "Batch mean Validation Loss: 0.083311\n",
      "Batch mean Validation Loss: 0.102515\n",
      "Accuracy of the network on the 10000 validation set: 93.89698456211225 %\n",
      "current acc=93.89698456211225, prev_best_acc=94.14225941422595\n",
      "Train Epoch: 22 [0/16170 (0%)]\tLoss: 0.319249\n",
      "Train Epoch: 22 [6400/16170 (40%)]\tLoss: 0.141390\n",
      "Train Epoch: 22 [12800/16170 (79%)]\tLoss: 0.133181\n",
      "Batch mean Validation Loss: 0.087788\n",
      "Batch mean Validation Loss: 0.094441\n",
      "Accuracy of the network on the 10000 validation set: 93.17558793824846 %\n",
      "current acc=93.17558793824846, prev_best_acc=94.14225941422595\n",
      "Train Epoch: 23 [0/16170 (0%)]\tLoss: 0.130477\n",
      "Train Epoch: 23 [6400/16170 (40%)]\tLoss: 0.112572\n",
      "Train Epoch: 23 [12800/16170 (79%)]\tLoss: 0.084197\n",
      "Batch mean Validation Loss: 0.088267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch mean Validation Loss: 0.102309\n",
      "Accuracy of the network on the 10000 validation set: 94.02683595440773 %\n",
      "current acc=94.02683595440773, prev_best_acc=94.14225941422595\n",
      "Train Epoch: 24 [0/16170 (0%)]\tLoss: 0.091845\n",
      "Train Epoch: 24 [6400/16170 (40%)]\tLoss: 0.117756\n",
      "Train Epoch: 24 [12800/16170 (79%)]\tLoss: 0.112647\n",
      "Batch mean Validation Loss: 0.087848\n",
      "Batch mean Validation Loss: 0.101614\n",
      "Accuracy of the network on the 10000 validation set: 93.49300245274853 %\n",
      "current acc=93.49300245274853, prev_best_acc=94.14225941422595\n",
      "Train Epoch: 25 [0/16170 (0%)]\tLoss: 0.116283\n",
      "Train Epoch: 25 [6400/16170 (40%)]\tLoss: 0.082701\n",
      "Train Epoch: 25 [12800/16170 (79%)]\tLoss: 0.145371\n",
      "Batch mean Validation Loss: 0.088205\n",
      "Batch mean Validation Loss: 0.091996\n",
      "Accuracy of the network on the 10000 validation set: 93.78156110229403 %\n",
      "current acc=93.78156110229403, prev_best_acc=94.14225941422595\n",
      "Train Epoch: 26 [0/16170 (0%)]\tLoss: 0.185984\n",
      "Train Epoch: 26 [6400/16170 (40%)]\tLoss: 0.098554\n",
      "Train Epoch: 26 [12800/16170 (79%)]\tLoss: 0.085021\n",
      "Batch mean Validation Loss: 0.081893\n",
      "Batch mean Validation Loss: 0.093166\n",
      "Accuracy of the network on the 10000 validation set: 94.12783148174867 %\n",
      "current acc=94.12783148174867, prev_best_acc=94.14225941422595\n",
      "Train Epoch: 27 [0/16170 (0%)]\tLoss: 0.117382\n",
      "Train Epoch: 27 [6400/16170 (40%)]\tLoss: 0.113621\n",
      "Train Epoch: 27 [12800/16170 (79%)]\tLoss: 0.139853\n",
      "Batch mean Validation Loss: 0.080812\n",
      "Batch mean Validation Loss: 0.094040\n",
      "Accuracy of the network on the 10000 validation set: 94.92136776799885 %\n",
      "new best acc=94.92136776799885\n",
      "Train Epoch: 28 [0/16170 (0%)]\tLoss: 0.135982\n",
      "Train Epoch: 28 [6400/16170 (40%)]\tLoss: 0.203295\n",
      "Train Epoch: 28 [12800/16170 (79%)]\tLoss: 0.111628\n",
      "Batch mean Validation Loss: 0.078918\n",
      "Batch mean Validation Loss: 0.092065\n",
      "Accuracy of the network on the 10000 validation set: 95.88803924397634 %\n",
      "new best acc=95.88803924397634\n",
      "Train Epoch: 29 [0/16170 (0%)]\tLoss: 0.121403\n",
      "Train Epoch: 29 [6400/16170 (40%)]\tLoss: 0.088279\n",
      "Train Epoch: 29 [12800/16170 (79%)]\tLoss: 0.135430\n",
      "Batch mean Validation Loss: 0.078027\n",
      "Batch mean Validation Loss: 0.091529\n",
      "Accuracy of the network on the 10000 validation set: 95.55619679699899 %\n",
      "current acc=95.55619679699899, prev_best_acc=95.88803924397634\n",
      "Train Epoch: 30 [0/16170 (0%)]\tLoss: 0.123866\n",
      "Train Epoch: 30 [6400/16170 (40%)]\tLoss: 0.136859\n",
      "Train Epoch: 30 [12800/16170 (79%)]\tLoss: 0.279653\n",
      "Batch mean Validation Loss: 0.072506\n",
      "Batch mean Validation Loss: 0.092949\n",
      "Accuracy of the network on the 10000 validation set: 96.13331409609003 %\n",
      "new best acc=96.13331409609003\n",
      "Train Epoch: 31 [0/16170 (0%)]\tLoss: 0.136251\n",
      "Train Epoch: 31 [6400/16170 (40%)]\tLoss: 0.136057\n",
      "Train Epoch: 31 [12800/16170 (79%)]\tLoss: 0.206287\n",
      "Batch mean Validation Loss: 0.066975\n",
      "Batch mean Validation Loss: 0.085283\n",
      "Accuracy of the network on the 10000 validation set: 95.03679122781705 %\n",
      "current acc=95.03679122781705, prev_best_acc=96.13331409609003\n",
      "Train Epoch: 32 [0/16170 (0%)]\tLoss: 0.145917\n",
      "Train Epoch: 32 [6400/16170 (40%)]\tLoss: 0.104623\n",
      "Train Epoch: 32 [12800/16170 (79%)]\tLoss: 0.320268\n",
      "Batch mean Validation Loss: 0.075147\n",
      "Batch mean Validation Loss: 0.086640\n",
      "Accuracy of the network on the 10000 validation set: 96.20545375847641 %\n",
      "new best acc=96.20545375847641\n",
      "Train Epoch: 33 [0/16170 (0%)]\tLoss: 0.169477\n",
      "Train Epoch: 33 [6400/16170 (40%)]\tLoss: 0.123405\n",
      "Train Epoch: 33 [12800/16170 (79%)]\tLoss: 0.089492\n",
      "Batch mean Validation Loss: 0.069691\n",
      "Batch mean Validation Loss: 0.077671\n",
      "Accuracy of the network on the 10000 validation set: 96.07560236618093 %\n",
      "current acc=96.07560236618093, prev_best_acc=96.20545375847641\n",
      "Train Epoch: 34 [0/16170 (0%)]\tLoss: 0.115452\n",
      "Train Epoch: 34 [6400/16170 (40%)]\tLoss: 0.156129\n",
      "Train Epoch: 34 [12800/16170 (79%)]\tLoss: 0.141009\n",
      "Batch mean Validation Loss: 0.067021\n",
      "Batch mean Validation Loss: 0.079986\n",
      "Accuracy of the network on the 10000 validation set: 96.14774202856731 %\n",
      "current acc=96.14774202856731, prev_best_acc=96.20545375847641\n",
      "Train Epoch: 35 [0/16170 (0%)]\tLoss: 0.074000\n",
      "Train Epoch: 35 [6400/16170 (40%)]\tLoss: 0.098057\n",
      "Train Epoch: 35 [12800/16170 (79%)]\tLoss: 0.168150\n",
      "Batch mean Validation Loss: 0.068803\n",
      "Batch mean Validation Loss: 0.079939\n",
      "Accuracy of the network on the 10000 validation set: 95.81589958158996 %\n",
      "current acc=95.81589958158996, prev_best_acc=96.20545375847641\n",
      "Train Epoch: 36 [0/16170 (0%)]\tLoss: 0.200024\n",
      "Train Epoch: 36 [6400/16170 (40%)]\tLoss: 0.117038\n",
      "Train Epoch: 36 [12800/16170 (79%)]\tLoss: 0.134547\n",
      "Batch mean Validation Loss: 0.068496\n",
      "Batch mean Validation Loss: 0.066228\n",
      "Accuracy of the network on the 10000 validation set: 96.53729620545376 %\n",
      "new best acc=96.53729620545376\n",
      "Train Epoch: 37 [0/16170 (0%)]\tLoss: 0.091380\n",
      "Train Epoch: 37 [6400/16170 (40%)]\tLoss: 0.099969\n",
      "Train Epoch: 37 [12800/16170 (79%)]\tLoss: 0.133042\n",
      "Batch mean Validation Loss: 0.063348\n",
      "Batch mean Validation Loss: 0.067262\n",
      "Accuracy of the network on the 10000 validation set: 96.9989900447266 %\n",
      "new best acc=96.9989900447266\n",
      "Train Epoch: 38 [0/16170 (0%)]\tLoss: 0.124353\n",
      "Train Epoch: 38 [6400/16170 (40%)]\tLoss: 0.070525\n",
      "Train Epoch: 38 [12800/16170 (79%)]\tLoss: 0.075781\n",
      "Batch mean Validation Loss: 0.064232\n",
      "Batch mean Validation Loss: 0.069849\n",
      "Accuracy of the network on the 10000 validation set: 96.40744481315828 %\n",
      "current acc=96.40744481315828, prev_best_acc=96.9989900447266\n",
      "Train Epoch: 39 [0/16170 (0%)]\tLoss: 0.083393\n",
      "Train Epoch: 39 [6400/16170 (40%)]\tLoss: 0.113217\n",
      "Train Epoch: 39 [12800/16170 (79%)]\tLoss: 0.076959\n",
      "Batch mean Validation Loss: 0.057273\n",
      "Batch mean Validation Loss: 0.066408\n",
      "Accuracy of the network on the 10000 validation set: 96.84028278747655 %\n",
      "current acc=96.84028278747655, prev_best_acc=96.9989900447266\n",
      "Train Epoch: 40 [0/16170 (0%)]\tLoss: 0.136388\n",
      "Train Epoch: 40 [6400/16170 (40%)]\tLoss: 0.118026\n",
      "Train Epoch: 40 [12800/16170 (79%)]\tLoss: 0.083363\n",
      "Batch mean Validation Loss: 0.063359\n",
      "Batch mean Validation Loss: 0.075962\n",
      "Accuracy of the network on the 10000 validation set: 97.18655316693118 %\n",
      "new best acc=97.18655316693118\n",
      "Train Epoch: 41 [0/16170 (0%)]\tLoss: 0.113973\n",
      "Train Epoch: 41 [6400/16170 (40%)]\tLoss: 0.044604\n",
      "Train Epoch: 41 [12800/16170 (79%)]\tLoss: 0.178130\n",
      "Batch mean Validation Loss: 0.063918\n",
      "Batch mean Validation Loss: 0.065632\n",
      "Accuracy of the network on the 10000 validation set: 97.56167941134035 %\n",
      "new best acc=97.56167941134035\n",
      "Train Epoch: 42 [0/16170 (0%)]\tLoss: 0.131366\n",
      "Train Epoch: 42 [6400/16170 (40%)]\tLoss: 0.089377\n",
      "Train Epoch: 42 [12800/16170 (79%)]\tLoss: 0.098549\n",
      "Batch mean Validation Loss: 0.054175\n",
      "Batch mean Validation Loss: 0.069889\n",
      "Accuracy of the network on the 10000 validation set: 97.51839561390852 %\n",
      "current acc=97.51839561390852, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 43 [0/16170 (0%)]\tLoss: 0.095415\n",
      "Train Epoch: 43 [6400/16170 (40%)]\tLoss: 0.107632\n",
      "Train Epoch: 43 [12800/16170 (79%)]\tLoss: 0.140971\n",
      "Batch mean Validation Loss: 0.056883\n",
      "Batch mean Validation Loss: 0.058873\n",
      "Accuracy of the network on the 10000 validation set: 97.46068388399942 %\n",
      "current acc=97.46068388399942, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 44 [0/16170 (0%)]\tLoss: 0.101738\n",
      "Train Epoch: 44 [6400/16170 (40%)]\tLoss: 0.117675\n",
      "Train Epoch: 44 [12800/16170 (79%)]\tLoss: 0.122916\n",
      "Batch mean Validation Loss: 0.053040\n",
      "Batch mean Validation Loss: 0.066531\n",
      "Accuracy of the network on the 10000 validation set: 97.46068388399942 %\n",
      "current acc=97.46068388399942, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 45 [0/16170 (0%)]\tLoss: 0.189028\n",
      "Train Epoch: 45 [6400/16170 (40%)]\tLoss: 0.109504\n",
      "Train Epoch: 45 [12800/16170 (79%)]\tLoss: 0.143202\n",
      "Batch mean Validation Loss: 0.052984\n",
      "Batch mean Validation Loss: 0.064651\n",
      "Accuracy of the network on the 10000 validation set: 97.43182801904487 %\n",
      "current acc=97.43182801904487, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 46 [0/16170 (0%)]\tLoss: 0.079161\n",
      "Train Epoch: 46 [6400/16170 (40%)]\tLoss: 0.099332\n",
      "Train Epoch: 46 [12800/16170 (79%)]\tLoss: 0.093051\n",
      "Batch mean Validation Loss: 0.055844\n",
      "Batch mean Validation Loss: 0.058570\n",
      "Accuracy of the network on the 10000 validation set: 97.4174000865676 %\n",
      "current acc=97.4174000865676, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 47 [0/16170 (0%)]\tLoss: 0.112929\n",
      "Train Epoch: 47 [6400/16170 (40%)]\tLoss: 0.123980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47 [12800/16170 (79%)]\tLoss: 0.096793\n",
      "Batch mean Validation Loss: 0.047823\n",
      "Batch mean Validation Loss: 0.058298\n",
      "Accuracy of the network on the 10000 validation set: 97.50396768143125 %\n",
      "current acc=97.50396768143125, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 48 [0/16170 (0%)]\tLoss: 0.172936\n",
      "Train Epoch: 48 [6400/16170 (40%)]\tLoss: 0.125561\n",
      "Train Epoch: 48 [12800/16170 (79%)]\tLoss: 0.068829\n",
      "Batch mean Validation Loss: 0.047746\n",
      "Batch mean Validation Loss: 0.067614\n",
      "Accuracy of the network on the 10000 validation set: 97.38854422161305 %\n",
      "current acc=97.38854422161305, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 49 [0/16170 (0%)]\tLoss: 0.088861\n",
      "Train Epoch: 49 [6400/16170 (40%)]\tLoss: 0.073160\n",
      "Train Epoch: 49 [12800/16170 (79%)]\tLoss: 0.100551\n",
      "Batch mean Validation Loss: 0.054690\n",
      "Batch mean Validation Loss: 0.070877\n",
      "Accuracy of the network on the 10000 validation set: 97.50396768143125 %\n",
      "current acc=97.50396768143125, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 50 [0/16170 (0%)]\tLoss: 0.199468\n",
      "Train Epoch: 50 [6400/16170 (40%)]\tLoss: 0.162248\n",
      "Train Epoch: 50 [12800/16170 (79%)]\tLoss: 0.099895\n",
      "Batch mean Validation Loss: 0.055225\n",
      "Batch mean Validation Loss: 0.067419\n",
      "Accuracy of the network on the 10000 validation set: 97.37411628913577 %\n",
      "current acc=97.37411628913577, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 51 [0/16170 (0%)]\tLoss: 0.126635\n",
      "Train Epoch: 51 [6400/16170 (40%)]\tLoss: 0.098116\n",
      "Train Epoch: 51 [12800/16170 (79%)]\tLoss: 0.101885\n",
      "Batch mean Validation Loss: 0.047831\n",
      "Batch mean Validation Loss: 0.065370\n",
      "Accuracy of the network on the 10000 validation set: 97.50396768143125 %\n",
      "current acc=97.50396768143125, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 52 [0/16170 (0%)]\tLoss: 0.082638\n",
      "Train Epoch: 52 [6400/16170 (40%)]\tLoss: 0.112163\n",
      "Train Epoch: 52 [12800/16170 (79%)]\tLoss: 0.153954\n",
      "Batch mean Validation Loss: 0.047062\n",
      "Batch mean Validation Loss: 0.068356\n",
      "Accuracy of the network on the 10000 validation set: 97.5328235463858 %\n",
      "current acc=97.5328235463858, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 53 [0/16170 (0%)]\tLoss: 0.232394\n",
      "Train Epoch: 53 [6400/16170 (40%)]\tLoss: 0.131646\n",
      "Train Epoch: 53 [12800/16170 (79%)]\tLoss: 0.152333\n",
      "Batch mean Validation Loss: 0.049646\n",
      "Batch mean Validation Loss: 0.057764\n",
      "Accuracy of the network on the 10000 validation set: 97.50396768143125 %\n",
      "current acc=97.50396768143125, prev_best_acc=97.56167941134035\n",
      "Train Epoch: 54 [0/16170 (0%)]\tLoss: 0.081722\n",
      "Train Epoch: 54 [6400/16170 (40%)]\tLoss: 0.062831\n",
      "Train Epoch: 54 [12800/16170 (79%)]\tLoss: 0.122186\n",
      "Batch mean Validation Loss: 0.047996\n",
      "Batch mean Validation Loss: 0.053744\n",
      "Accuracy of the network on the 10000 validation set: 97.5905352762949 %\n",
      "new best acc=97.5905352762949\n",
      "Train Epoch: 55 [0/16170 (0%)]\tLoss: 0.171196\n",
      "Train Epoch: 55 [6400/16170 (40%)]\tLoss: 0.104867\n",
      "Train Epoch: 55 [12800/16170 (79%)]\tLoss: 0.063962\n",
      "Batch mean Validation Loss: 0.050242\n",
      "Batch mean Validation Loss: 0.059147\n",
      "Accuracy of the network on the 10000 validation set: 97.63381907372674 %\n",
      "new best acc=97.63381907372674\n",
      "Train Epoch: 56 [0/16170 (0%)]\tLoss: 0.101066\n",
      "Train Epoch: 56 [6400/16170 (40%)]\tLoss: 0.160187\n",
      "Train Epoch: 56 [12800/16170 (79%)]\tLoss: 0.168121\n",
      "Batch mean Validation Loss: 0.047929\n",
      "Batch mean Validation Loss: 0.060955\n",
      "Accuracy of the network on the 10000 validation set: 97.54725147886307 %\n",
      "current acc=97.54725147886307, prev_best_acc=97.63381907372674\n",
      "Train Epoch: 57 [0/16170 (0%)]\tLoss: 0.117197\n",
      "Train Epoch: 57 [6400/16170 (40%)]\tLoss: 0.086130\n",
      "Train Epoch: 57 [12800/16170 (79%)]\tLoss: 0.091550\n",
      "Batch mean Validation Loss: 0.051877\n",
      "Batch mean Validation Loss: 0.056063\n",
      "Accuracy of the network on the 10000 validation set: 97.5328235463858 %\n",
      "current acc=97.5328235463858, prev_best_acc=97.63381907372674\n",
      "Train Epoch: 58 [0/16170 (0%)]\tLoss: 0.082878\n",
      "Train Epoch: 58 [6400/16170 (40%)]\tLoss: 0.218035\n",
      "Train Epoch: 58 [12800/16170 (79%)]\tLoss: 0.066849\n",
      "Batch mean Validation Loss: 0.042728\n",
      "Batch mean Validation Loss: 0.052464\n",
      "Accuracy of the network on the 10000 validation set: 97.61939114124947 %\n",
      "current acc=97.61939114124947, prev_best_acc=97.63381907372674\n",
      "Train Epoch: 59 [0/16170 (0%)]\tLoss: 0.139391\n",
      "Train Epoch: 59 [6400/16170 (40%)]\tLoss: 0.155497\n",
      "Train Epoch: 59 [12800/16170 (79%)]\tLoss: 0.097471\n",
      "Batch mean Validation Loss: 0.043584\n",
      "Batch mean Validation Loss: 0.052279\n",
      "Accuracy of the network on the 10000 validation set: 97.44625595152215 %\n",
      "current acc=97.44625595152215, prev_best_acc=97.63381907372674\n",
      "Train Epoch: 60 [0/16170 (0%)]\tLoss: 0.077046\n",
      "Train Epoch: 60 [6400/16170 (40%)]\tLoss: 0.055374\n",
      "Train Epoch: 60 [12800/16170 (79%)]\tLoss: 0.204611\n",
      "Batch mean Validation Loss: 0.049590\n",
      "Batch mean Validation Loss: 0.064698\n",
      "Accuracy of the network on the 10000 validation set: 97.4751118164767 %\n",
      "current acc=97.4751118164767, prev_best_acc=97.63381907372674\n",
      "Train Epoch: 61 [0/16170 (0%)]\tLoss: 0.254275\n",
      "Train Epoch: 61 [6400/16170 (40%)]\tLoss: 0.105127\n",
      "Train Epoch: 61 [12800/16170 (79%)]\tLoss: 0.120020\n",
      "Batch mean Validation Loss: 0.053343\n",
      "Batch mean Validation Loss: 0.054186\n",
      "Accuracy of the network on the 10000 validation set: 97.7203866685904 %\n",
      "new best acc=97.7203866685904\n",
      "Train Epoch: 62 [0/16170 (0%)]\tLoss: 0.147301\n",
      "Train Epoch: 62 [6400/16170 (40%)]\tLoss: 0.187984\n",
      "Train Epoch: 62 [12800/16170 (79%)]\tLoss: 0.090723\n",
      "Batch mean Validation Loss: 0.049552\n",
      "Batch mean Validation Loss: 0.052764\n",
      "Accuracy of the network on the 10000 validation set: 97.7203866685904 %\n",
      "current acc=97.7203866685904, prev_best_acc=97.7203866685904\n",
      "Train Epoch: 63 [0/16170 (0%)]\tLoss: 0.109988\n",
      "Train Epoch: 63 [6400/16170 (40%)]\tLoss: 0.062408\n",
      "Train Epoch: 63 [12800/16170 (79%)]\tLoss: 0.126561\n",
      "Batch mean Validation Loss: 0.048355\n",
      "Batch mean Validation Loss: 0.054113\n",
      "Accuracy of the network on the 10000 validation set: 97.5905352762949 %\n",
      "current acc=97.5905352762949, prev_best_acc=97.7203866685904\n",
      "Train Epoch: 64 [0/16170 (0%)]\tLoss: 0.046176\n",
      "Train Epoch: 64 [6400/16170 (40%)]\tLoss: 0.105285\n",
      "Train Epoch: 64 [12800/16170 (79%)]\tLoss: 0.190389\n",
      "Batch mean Validation Loss: 0.045827\n",
      "Batch mean Validation Loss: 0.054930\n",
      "Accuracy of the network on the 10000 validation set: 97.51839561390852 %\n",
      "current acc=97.51839561390852, prev_best_acc=97.7203866685904\n",
      "Train Epoch: 65 [0/16170 (0%)]\tLoss: 0.300875\n",
      "Train Epoch: 65 [6400/16170 (40%)]\tLoss: 0.087374\n",
      "Train Epoch: 65 [12800/16170 (79%)]\tLoss: 0.083269\n",
      "Batch mean Validation Loss: 0.044707\n",
      "Batch mean Validation Loss: 0.056390\n",
      "Accuracy of the network on the 10000 validation set: 97.61939114124947 %\n",
      "current acc=97.61939114124947, prev_best_acc=97.7203866685904\n",
      "Train Epoch: 66 [0/16170 (0%)]\tLoss: 0.063347\n",
      "Train Epoch: 66 [6400/16170 (40%)]\tLoss: 0.081334\n",
      "Train Epoch: 66 [12800/16170 (79%)]\tLoss: 0.099094\n",
      "Batch mean Validation Loss: 0.042176\n",
      "Batch mean Validation Loss: 0.060700\n",
      "Accuracy of the network on the 10000 validation set: 97.57610734381763 %\n",
      "current acc=97.57610734381763, prev_best_acc=97.7203866685904\n",
      "Train Epoch: 67 [0/16170 (0%)]\tLoss: 0.064697\n",
      "Train Epoch: 67 [6400/16170 (40%)]\tLoss: 0.187408\n",
      "Train Epoch: 67 [12800/16170 (79%)]\tLoss: 0.341746\n",
      "Batch mean Validation Loss: 0.044142\n",
      "Batch mean Validation Loss: 0.054434\n",
      "Accuracy of the network on the 10000 validation set: 97.87909392584042 %\n",
      "new best acc=97.87909392584042\n",
      "Train Epoch: 68 [0/16170 (0%)]\tLoss: 0.095573\n",
      "Train Epoch: 68 [6400/16170 (40%)]\tLoss: 0.143347\n",
      "Train Epoch: 68 [12800/16170 (79%)]\tLoss: 0.086417\n",
      "Batch mean Validation Loss: 0.041496\n",
      "Batch mean Validation Loss: 0.049741\n",
      "Accuracy of the network on the 10000 validation set: 97.80695426345405 %\n",
      "current acc=97.80695426345405, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 69 [0/16170 (0%)]\tLoss: 0.105866\n",
      "Train Epoch: 69 [6400/16170 (40%)]\tLoss: 0.066476\n",
      "Train Epoch: 69 [12800/16170 (79%)]\tLoss: 0.113833\n",
      "Batch mean Validation Loss: 0.045706\n",
      "Batch mean Validation Loss: 0.056612\n",
      "Accuracy of the network on the 10000 validation set: 97.79252633097677 %\n",
      "current acc=97.79252633097677, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 70 [0/16170 (0%)]\tLoss: 0.102441\n",
      "Train Epoch: 70 [6400/16170 (40%)]\tLoss: 0.090831\n",
      "Train Epoch: 70 [12800/16170 (79%)]\tLoss: 0.239906\n",
      "Batch mean Validation Loss: 0.044513\n",
      "Batch mean Validation Loss: 0.052564\n",
      "Accuracy of the network on the 10000 validation set: 97.80695426345405 %\n",
      "current acc=97.80695426345405, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 71 [0/16170 (0%)]\tLoss: 0.228455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 71 [6400/16170 (40%)]\tLoss: 0.059519\n",
      "Train Epoch: 71 [12800/16170 (79%)]\tLoss: 0.121167\n",
      "Batch mean Validation Loss: 0.044871\n",
      "Batch mean Validation Loss: 0.051161\n",
      "Accuracy of the network on the 10000 validation set: 97.7780983984995 %\n",
      "current acc=97.7780983984995, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 72 [0/16170 (0%)]\tLoss: 0.057218\n",
      "Train Epoch: 72 [6400/16170 (40%)]\tLoss: 0.072844\n",
      "Train Epoch: 72 [12800/16170 (79%)]\tLoss: 0.207410\n",
      "Batch mean Validation Loss: 0.047394\n",
      "Batch mean Validation Loss: 0.057387\n",
      "Accuracy of the network on the 10000 validation set: 97.5328235463858 %\n",
      "current acc=97.5328235463858, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 73 [0/16170 (0%)]\tLoss: 0.070411\n",
      "Train Epoch: 73 [6400/16170 (40%)]\tLoss: 0.075721\n",
      "Train Epoch: 73 [12800/16170 (79%)]\tLoss: 0.082055\n",
      "Batch mean Validation Loss: 0.043895\n",
      "Batch mean Validation Loss: 0.052219\n",
      "Accuracy of the network on the 10000 validation set: 97.48953974895397 %\n",
      "current acc=97.48953974895397, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 74 [0/16170 (0%)]\tLoss: 0.085817\n",
      "Train Epoch: 74 [6400/16170 (40%)]\tLoss: 0.138017\n",
      "Train Epoch: 74 [12800/16170 (79%)]\tLoss: 0.118842\n",
      "Batch mean Validation Loss: 0.043109\n",
      "Batch mean Validation Loss: 0.050551\n",
      "Accuracy of the network on the 10000 validation set: 97.67710287115857 %\n",
      "current acc=97.67710287115857, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 75 [0/16170 (0%)]\tLoss: 0.199443\n",
      "Train Epoch: 75 [6400/16170 (40%)]\tLoss: 0.083689\n",
      "Train Epoch: 75 [12800/16170 (79%)]\tLoss: 0.143735\n",
      "Batch mean Validation Loss: 0.047410\n",
      "Batch mean Validation Loss: 0.050715\n",
      "Accuracy of the network on the 10000 validation set: 97.69153080363584 %\n",
      "current acc=97.69153080363584, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 76 [0/16170 (0%)]\tLoss: 0.105894\n",
      "Train Epoch: 76 [6400/16170 (40%)]\tLoss: 0.061191\n",
      "Train Epoch: 76 [12800/16170 (79%)]\tLoss: 0.086850\n",
      "Batch mean Validation Loss: 0.040230\n",
      "Batch mean Validation Loss: 0.054037\n",
      "Accuracy of the network on the 10000 validation set: 97.56167941134035 %\n",
      "current acc=97.56167941134035, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 77 [0/16170 (0%)]\tLoss: 0.182454\n",
      "Train Epoch: 77 [6400/16170 (40%)]\tLoss: 0.142258\n",
      "Train Epoch: 77 [12800/16170 (79%)]\tLoss: 0.116974\n",
      "Batch mean Validation Loss: 0.055730\n",
      "Batch mean Validation Loss: 0.047851\n",
      "Accuracy of the network on the 10000 validation set: 97.63381907372674 %\n",
      "current acc=97.63381907372674, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 78 [0/16170 (0%)]\tLoss: 0.208048\n",
      "Train Epoch: 78 [6400/16170 (40%)]\tLoss: 0.079779\n",
      "Train Epoch: 78 [12800/16170 (79%)]\tLoss: 0.076312\n",
      "Batch mean Validation Loss: 0.044621\n",
      "Batch mean Validation Loss: 0.053134\n",
      "Accuracy of the network on the 10000 validation set: 97.79252633097677 %\n",
      "current acc=97.79252633097677, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 79 [0/16170 (0%)]\tLoss: 0.125834\n",
      "Train Epoch: 79 [6400/16170 (40%)]\tLoss: 0.110374\n",
      "Train Epoch: 79 [12800/16170 (79%)]\tLoss: 0.081879\n",
      "Batch mean Validation Loss: 0.043913\n",
      "Batch mean Validation Loss: 0.052994\n",
      "Accuracy of the network on the 10000 validation set: 97.57610734381763 %\n",
      "current acc=97.57610734381763, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 80 [0/16170 (0%)]\tLoss: 0.167397\n",
      "Train Epoch: 80 [6400/16170 (40%)]\tLoss: 0.151748\n",
      "Train Epoch: 80 [12800/16170 (79%)]\tLoss: 0.085182\n",
      "Batch mean Validation Loss: 0.048488\n",
      "Batch mean Validation Loss: 0.049637\n",
      "Accuracy of the network on the 10000 validation set: 97.82138219593132 %\n",
      "current acc=97.82138219593132, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 81 [0/16170 (0%)]\tLoss: 0.216326\n",
      "Train Epoch: 81 [6400/16170 (40%)]\tLoss: 0.100182\n",
      "Train Epoch: 81 [12800/16170 (79%)]\tLoss: 0.088981\n",
      "Batch mean Validation Loss: 0.045942\n",
      "Batch mean Validation Loss: 0.057755\n",
      "Accuracy of the network on the 10000 validation set: 97.60496320877218 %\n",
      "current acc=97.60496320877218, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 82 [0/16170 (0%)]\tLoss: 0.116701\n",
      "Train Epoch: 82 [6400/16170 (40%)]\tLoss: 0.137245\n",
      "Train Epoch: 82 [12800/16170 (79%)]\tLoss: 0.081012\n",
      "Batch mean Validation Loss: 0.046873\n",
      "Batch mean Validation Loss: 0.056139\n",
      "Accuracy of the network on the 10000 validation set: 97.25869282931755 %\n",
      "current acc=97.25869282931755, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 83 [0/16170 (0%)]\tLoss: 0.110472\n",
      "Train Epoch: 83 [6400/16170 (40%)]\tLoss: 0.094390\n",
      "Train Epoch: 83 [12800/16170 (79%)]\tLoss: 0.073997\n",
      "Batch mean Validation Loss: 0.041149\n",
      "Batch mean Validation Loss: 0.048635\n",
      "Accuracy of the network on the 10000 validation set: 97.63381907372674 %\n",
      "current acc=97.63381907372674, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 84 [0/16170 (0%)]\tLoss: 0.111544\n",
      "Train Epoch: 84 [6400/16170 (40%)]\tLoss: 0.065186\n",
      "Train Epoch: 84 [12800/16170 (79%)]\tLoss: 0.073020\n",
      "Batch mean Validation Loss: 0.041678\n",
      "Batch mean Validation Loss: 0.051650\n",
      "Accuracy of the network on the 10000 validation set: 97.60496320877218 %\n",
      "current acc=97.60496320877218, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 85 [0/16170 (0%)]\tLoss: 0.089287\n",
      "Train Epoch: 85 [6400/16170 (40%)]\tLoss: 0.069450\n",
      "Train Epoch: 85 [12800/16170 (79%)]\tLoss: 0.097063\n",
      "Batch mean Validation Loss: 0.044459\n",
      "Batch mean Validation Loss: 0.048450\n",
      "Accuracy of the network on the 10000 validation set: 97.54725147886307 %\n",
      "current acc=97.54725147886307, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 86 [0/16170 (0%)]\tLoss: 0.186069\n",
      "Train Epoch: 86 [6400/16170 (40%)]\tLoss: 0.121310\n",
      "Train Epoch: 86 [12800/16170 (79%)]\tLoss: 0.060856\n",
      "Batch mean Validation Loss: 0.042628\n",
      "Batch mean Validation Loss: 0.051511\n",
      "Accuracy of the network on the 10000 validation set: 97.61939114124947 %\n",
      "current acc=97.61939114124947, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 87 [0/16170 (0%)]\tLoss: 0.070529\n",
      "Train Epoch: 87 [6400/16170 (40%)]\tLoss: 0.236799\n",
      "Train Epoch: 87 [12800/16170 (79%)]\tLoss: 0.203495\n",
      "Batch mean Validation Loss: 0.039517\n",
      "Batch mean Validation Loss: 0.043948\n",
      "Accuracy of the network on the 10000 validation set: 97.80695426345405 %\n",
      "current acc=97.80695426345405, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 88 [0/16170 (0%)]\tLoss: 0.112253\n",
      "Train Epoch: 88 [6400/16170 (40%)]\tLoss: 0.079900\n",
      "Train Epoch: 88 [12800/16170 (79%)]\tLoss: 0.112089\n",
      "Batch mean Validation Loss: 0.046170\n",
      "Batch mean Validation Loss: 0.049875\n",
      "Accuracy of the network on the 10000 validation set: 97.54725147886307 %\n",
      "current acc=97.54725147886307, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 89 [0/16170 (0%)]\tLoss: 0.156651\n",
      "Train Epoch: 89 [6400/16170 (40%)]\tLoss: 0.170350\n",
      "Train Epoch: 89 [12800/16170 (79%)]\tLoss: 0.109578\n",
      "Batch mean Validation Loss: 0.041894\n",
      "Batch mean Validation Loss: 0.049806\n",
      "Accuracy of the network on the 10000 validation set: 97.5905352762949 %\n",
      "current acc=97.5905352762949, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 90 [0/16170 (0%)]\tLoss: 0.098657\n",
      "Train Epoch: 90 [6400/16170 (40%)]\tLoss: 0.117899\n",
      "Train Epoch: 90 [12800/16170 (79%)]\tLoss: 0.095712\n",
      "Batch mean Validation Loss: 0.046000\n",
      "Batch mean Validation Loss: 0.056541\n",
      "Accuracy of the network on the 10000 validation set: 97.76367046602222 %\n",
      "current acc=97.76367046602222, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 91 [0/16170 (0%)]\tLoss: 0.121177\n",
      "Train Epoch: 91 [6400/16170 (40%)]\tLoss: 0.297833\n",
      "Train Epoch: 91 [12800/16170 (79%)]\tLoss: 0.072075\n",
      "Batch mean Validation Loss: 0.038896\n",
      "Batch mean Validation Loss: 0.047756\n",
      "Accuracy of the network on the 10000 validation set: 97.64824700620402 %\n",
      "current acc=97.64824700620402, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 92 [0/16170 (0%)]\tLoss: 0.086336\n",
      "Train Epoch: 92 [6400/16170 (40%)]\tLoss: 0.095346\n",
      "Train Epoch: 92 [12800/16170 (79%)]\tLoss: 0.074922\n",
      "Batch mean Validation Loss: 0.041497\n",
      "Batch mean Validation Loss: 0.051122\n",
      "Accuracy of the network on the 10000 validation set: 97.69153080363584 %\n",
      "current acc=97.69153080363584, prev_best_acc=97.87909392584042\n",
      "Train Epoch: 93 [0/16170 (0%)]\tLoss: 0.302160\n",
      "Train Epoch: 93 [6400/16170 (40%)]\tLoss: 0.186911\n",
      "Train Epoch: 93 [12800/16170 (79%)]\tLoss: 0.170954\n",
      "Batch mean Validation Loss: 0.038777\n",
      "Batch mean Validation Loss: 0.047768\n",
      "Accuracy of the network on the 10000 validation set: 97.93680565574954 %\n",
      "new best acc=97.93680565574954\n",
      "Train Epoch: 94 [0/16170 (0%)]\tLoss: 0.070458\n",
      "Train Epoch: 94 [6400/16170 (40%)]\tLoss: 0.149932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 94 [12800/16170 (79%)]\tLoss: 0.112104\n",
      "Batch mean Validation Loss: 0.043545\n",
      "Batch mean Validation Loss: 0.050591\n",
      "Accuracy of the network on the 10000 validation set: 97.8358101284086 %\n",
      "current acc=97.8358101284086, prev_best_acc=97.93680565574954\n",
      "Train Epoch: 95 [0/16170 (0%)]\tLoss: 0.114586\n",
      "Train Epoch: 95 [6400/16170 (40%)]\tLoss: 0.191477\n",
      "Train Epoch: 95 [12800/16170 (79%)]\tLoss: 0.096652\n",
      "Batch mean Validation Loss: 0.043164\n",
      "Batch mean Validation Loss: 0.052213\n",
      "Accuracy of the network on the 10000 validation set: 97.69153080363584 %\n",
      "current acc=97.69153080363584, prev_best_acc=97.93680565574954\n",
      "Train Epoch: 96 [0/16170 (0%)]\tLoss: 0.184067\n",
      "Train Epoch: 96 [6400/16170 (40%)]\tLoss: 0.177541\n",
      "Train Epoch: 96 [12800/16170 (79%)]\tLoss: 0.137091\n",
      "Batch mean Validation Loss: 0.039987\n",
      "Batch mean Validation Loss: 0.044793\n",
      "Accuracy of the network on the 10000 validation set: 97.76367046602222 %\n",
      "current acc=97.76367046602222, prev_best_acc=97.93680565574954\n",
      "Train Epoch: 97 [0/16170 (0%)]\tLoss: 0.045294\n",
      "Train Epoch: 97 [6400/16170 (40%)]\tLoss: 0.057951\n",
      "Train Epoch: 97 [12800/16170 (79%)]\tLoss: 0.095434\n",
      "Batch mean Validation Loss: 0.044584\n",
      "Batch mean Validation Loss: 0.045511\n",
      "Accuracy of the network on the 10000 validation set: 97.8935218583177 %\n",
      "current acc=97.8935218583177, prev_best_acc=97.93680565574954\n",
      "Train Epoch: 98 [0/16170 (0%)]\tLoss: 0.182358\n",
      "Train Epoch: 98 [6400/16170 (40%)]\tLoss: 0.116491\n",
      "Train Epoch: 98 [12800/16170 (79%)]\tLoss: 0.116643\n",
      "Batch mean Validation Loss: 0.039475\n",
      "Batch mean Validation Loss: 0.051884\n",
      "Accuracy of the network on the 10000 validation set: 97.5905352762949 %\n",
      "current acc=97.5905352762949, prev_best_acc=97.93680565574954\n",
      "Train Epoch: 99 [0/16170 (0%)]\tLoss: 0.072471\n",
      "Train Epoch: 99 [6400/16170 (40%)]\tLoss: 0.224502\n",
      "Train Epoch: 99 [12800/16170 (79%)]\tLoss: 0.087137\n",
      "Batch mean Validation Loss: 0.040638\n",
      "Batch mean Validation Loss: 0.048962\n",
      "Accuracy of the network on the 10000 validation set: 97.64824700620402 %\n",
      "current acc=97.64824700620402, prev_best_acc=97.93680565574954\n",
      "best model saved\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '/Users/lhe339/Documents/GitHub/study/Pytorch/week1-DNN'\n",
    "best_acc = -1\n",
    "best_model = None\n",
    "for epoch in range(0, num_epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    acc = test()\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print(f'new best acc={best_acc}')\n",
    "    else:\n",
    "        print(f'current acc={acc}, prev_best_acc={best_acc}')\n",
    "\n",
    "state = {\n",
    "    'model_state': best_model.state_dict(),\n",
    "    'test_acc': best_acc\n",
    "}\n",
    "torch.save(state, OUTPUT_PATH+'/practice_nn.pt')  #훈련 끝나고 모델을 저장\n",
    "print('best model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "234470f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new data inference\n",
    "\n",
    "x = torch.normal(mean=6.9671e-06, std=0.4746, size=(1,54))\n",
    "out = model(x.to(device))\n",
    "out = torch.flatten(out).cpu().detach().numpy()\n",
    "predicted = np.where(out>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b701881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 클래스: [1]\n"
     ]
    }
   ],
   "source": [
    "print('예측 클래스:', predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd68085",
   "metadata": {},
   "source": [
    "## [HW] 3-layer neural network 를 구현하고 학습하세요(batch norm, drop out, activation function 자유 구성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c017364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class threee_layer_nn(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, drop_rate):\n",
    "        super(threee_layer_nn, self).__init__()\n",
    "        \n",
    "        layer1 = [nn.Linear(input_size, 128),\n",
    "                 nn.BatchNorm1d(128),\n",
    "                 nn.Dropout(drop_rate),\n",
    "                 nn.ReLU()]\n",
    "\n",
    "        layer2 = [nn.Linear(128, 64),\n",
    "                 nn.BatchNorm1d(64),\n",
    "                 nn.Dropout(drop_rate),\n",
    "                 nn.ReLU()]\n",
    "        \n",
    "        layer3 = [nn.Linear(64, output_size),\n",
    "                 nn.Sigmoid()]\n",
    "        \n",
    "        self.first_layer = nn.Sequential(*layer1)\n",
    "        self.second_layer = nn.Sequential(*layer2)\n",
    "        self.last_layer = nn.Sequential(*layer3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.self.first_layer(x)\n",
    "        x = self.self.second_layer(x)\n",
    "        out = self.self.last_layer(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f22da707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kward = {'drop_rate' : 0.2,\n",
    "            'input_size' : 256,\n",
    "            'output_size' : 2}\n",
    "\n",
    "training_kward = {'learning_rate' : 1e-2,\n",
    "                 'epoch' : 10}\n",
    "\n",
    "model = threee_layer_nn(**model_kward).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimization = optim.Adam(model.parameters(), lr=training_kwargs['learning_rate'])\n",
    "\n",
    "num_epochs = training_kwargs['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2da2a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threee_layer_nn(\n",
      "  (first_layer): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (second_layer): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (last_layer): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5777c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warning\n",
    "warning.filterwarning(\"ignore\")\n",
    "\n",
    "#loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    global criterion\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c701546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca6ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e431e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "#loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    global criterion\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data) #output: 64 x 1\n",
    "        output = output.squeeze(1) #output: 64\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test():\n",
    "    global criterion\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for batch_idx, (data, target) in enumerate (val_loader):\n",
    "            valid_loss = {'loss_val' : []}\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            loss_val = criterion(outputs, target)\n",
    "            valid_loss['loss_val'].append(loss_val.item())\n",
    "            \n",
    "            outputs = torch.flatten(outputs).cpu().detach().numpy()\n",
    "            target = torch.flatten(target).cpu().detach().numpy()\n",
    "            predicted = np.where(outputs>0.5, 1, 0)\n",
    "            \n",
    "            n_samples += len(target)\n",
    "            n_correct += (predicted == target).sum().item()\n",
    "            vl_mean = np.array(valid_loss['loss_val']).mean()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Batch mean Validation Loss: {:.6f}'.format(vl_mean))\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 validation set: {acc} %')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new data inference\n",
    "\n",
    "x = torch.normal(mean=6.9671e-06, std=0.4746, size=(1,54))\n",
    "out = model(x.to(device))\n",
    "out = torch.flatten(out).cpu().detach().numpy()\n",
    "predicted = np.where(out>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a860eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('예측 클래스:', predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
